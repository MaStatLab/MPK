{
    "contents" : "#' Fit Mixtures of Perturbed Gaussians \n#'\n#' This function generates a sample from the posterior of Mixtures of Perturbed Gaussians. \n#'\n#' @param Y Matrix of the data. Each row represents an observation.\n#' @param C Vector of the group label of each observation. Labels are integers starting from 1. \n#' @param prior A list giving the prior information. If unspecified, a default prior is used. \n#' The list includes the following hyparameters: \n#' \\code{K_0} Number of mixture components.\n#' \\code{epsilon0_range} Vector with minimum and maximum values for \\code{epsilon0}.\n#' \\code{merge_step} Introduce step to merge mixture components with small KL divergence. Default is \\code{merge_step = TRUE}.\n#' \\code{merge_par} Parameter controlling merging radius. Default is \\code{merge_par = 0.1}.\n#' @param mcmc A list giving the MCMC parameters. If unspecified, default parameters are used.  \n#' The list includes the following parameters: \\code{nburn} indicates the number of burn-in scans,\n#' \\code{nsave} indicates the number of scans to be saved,\n#' \\code{nskip} indicates the thinning interval,\n#' \\code{ndisplay} indicates the number of scans to be displayed on screen. \n#' The total number of scans is equal to  \\code{nburn + nsave*nskip}.\n#' @param state Initial state of the chain. At the moment only the latent variables Z can be initialized.\n#' @return A \\code{MPG} object. \n#' @details\n#' \\deqn{y_{i,j} = \\sum_{k=1}^{K}\\pi_{j,k}N(y_{i,j} | \\mu_{j,k}, \\Sigma_k )  }\n#' where \\eqn{i = 1, \\ldots, n_j} and \\eqn{j = 1, \\ldots, J}.\n#' where \n#' \\deqn{(w_{j,1}, \\ldots, w_{j,K}) \\sim Dirichlet(\\alpha_j/K) }\n#' @examples\n#' n = c(250, 250)\n#' p = 4\n#' \n#' Y1 = rbind( matrix( rnorm( n[1]*p), ncol = p), matrix( rnorm(n[2]*p) + 3, ncol = p))\n#' Y2 = rbind( matrix( rnorm( n[1]*p), ncol = p), matrix( rnorm(n[2]*p) + 4, ncol = p))\n#' Y = rbind(Y1, Y2)\n#' C = c( rep(1,sum(n)), rep(2,sum(n)))\n#' \n#' ans = mpg(Y, C)\nmpk <- function(Y, C, prior = NULL, mcmc = NULL, state = NULL)\n{\n  Y = as.matrix(Y)  \n  p = ncol(Y)\n  \n  J = length(unique(C))\n  if( sum( sort(unique(C)) == 1:J )  != J )\n  {\n    print(\"ERROR: unique(C) should look like 1, 2, ...\")\n    return(0);\n  }\n  C = C - 1\n  \n  if(is.null(prior))\n    prior = list()\n  if(is.null(prior$K))\n    prior$K = 10\n  if(is.null(prior$m_2))\n    prior$m_2 = colMeans(Y)\n  if(is.null(prior$nu_2))\n    prior$nu_2 = p+2\n  if(is.null(prior$nu_1))\n    prior$nu_1 = p+2\n  if(is.null(prior$Psi_2))\n    prior$Psi_2 = cov(Y)\n  if(is.null(prior$S_2))\n    prior$S_2 = 100*cov(Y)\n  if(is.null(prior$tau_k0))\n    prior$tau_k0 = c(4,4)\n  if(is.null(prior$tau_alpha))\n    prior$tau_alpha = c(1,1)\n  if(is.null(prior$tau_epsilon))\n    prior$tau_epsilon = p*J/2  \n  if(is.null(prior$tau_epsilon0))\n    prior$tau_epsilon0 = c(0.1,1) \n  if(is.null(prior$merge_step))\n    prior$merge_step = TRUE\n  if(is.null(prior$merge_par))\n    prior$merge_par = 0.1\n    \n      \n  if(is.null(mcmc))\n    mcmc = list()\n  if(is.null(mcmc$nburn))\n    mcmc$nburn = 5000\n  if(is.null(mcmc$nsave))\n    mcmc$nsave = 1000\n  if(is.null(mcmc$nskip))\n    mcmc$nskip = 1\n  if(is.null(mcmc$ndisplay))\n    mcmc$ndisplay = 100\n  if(is.null(mcmc$seed))\n    mcmc$seed = 42\n    \n\n  # set initial random seed for R here, it will propagate down to Rcpp\n  # but Armadillo's RNG will get set in MCMC class in gibbs.h\n  # NOTE: Rstudio seems to touch Armadillo's underlying RNG, so\n  # differing results may be seen when run from Rstudio, see comments\n  # from Dirk Eddelbuettel here:\n  #  https://github.com/RcppCore/RcppArmadillo/issues/11\n  set.seed(mcmc$seed) \n\n  \n  if(is.null(state))\n    state = list()  \n  \n  if(is.null(state$Z))\n    state$Z = kmeans(Y, 2*prior$K/3, iter.max = 100  )$cluster - 1\n  \n  if(is.null(state$epsilon))\n    state$epsilon = 1/rgamma(prior$K, shape = prior$tau_epsilon, \n                             rate = prior$tau_epsilon*prior$tau_epsilon0[1]/sum(prior$tau_epsilon0))\n  \n  if(is.null(state$epsilon_0))\n    state$epsilon_0 = prior$tau_epsilon0[1]/sum(prior$tau_epsilon0)\n  \n  if(is.null(state$Omega_1))\n    state$Omega_1 = solve(cov(Y))\n  \n  if(is.null(state$Omegas))\n  {    \n    N = tabulate(as.numeric(state$Z), prior$K)\n    state$Omegas = matrix(NA, nrow = p , ncol = p*prior$K)\n    for(k in 1:prior$K)\n    {\n      if(N[k] > p + 1)\n        state$Omegas[,seq(p*(k-1)+1,p*(k-1)+p)] = solve(cov(Y[state$Z==k,]))\n      else\n        state$Omegas[,seq(p*(k-1)+1,p*(k-1)+p)] = state$Omega_1   \n    }\n  }\n  \n  if(is.null(state$mu_0))\n  {\n    N = tabulate(as.numeric(state$Z), prior$K)\n    state$mu_0 = matrix(NA,nrow=p, ncol=prior$K)\n    for(k in 1:prior$K)\n    {\n      if(N[k] > 0)\n        state$mu_0[,k] = colMeans(Y[state$Z==k,]) \n      else\n        state$mu_0[,k] = colMeans(Y) + rnorm(p)  # do better if possible\n    }\n  }  \n  \n  if(is.null(state$mus))\n  {\n    state$mus = matrix(NA,nrow=J, ncol=p*prior$K)\n    for(k in 1:prior$K)\n    {\n      for(j in 1:J)\n        state$mus[j,seq(p*(k-1)+1,p*(k-1)+p)] = state$mu_0[,k] + rnorm(p) # do better if possible \n    }\n\n  }  \n  \n  if(is.null(state$alpha))\n    state$alpha = prior$tau_alpha[1]/sum(prior$tau_alpha)\n  \n  if(is.null(state$k_0))\n    state$k_0 = prior$tau_k0[1]/sum(prior$tau_k0)\n\n  if(is.null(state$w))\n    state$w = matrix(1/prior$K, nrow = J, ncol = prior$K)\n  \n  if(is.null(state$m_1))\n     state$m_1 = colMeans(Y)  \n\n  #####################################\n  \n  ans = fit(Y, C, prior, mcmc, state)\n  colnames(ans$data$Y) = colnames(Y)\n  ans$data$C = ans$data$C + 1\n  ans$chain$Z = ans$chain$Z + 1 \n  class(ans) = \"MPK\"\n  return(ans)\n  \n}\n",
    "created" : 1430413941566.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "615707948",
    "id" : "E8B794C8",
    "lastKnownWriteTime" : 1430597233,
    "path" : "~/Dropbox/Duke/Thesis/locally_tied_stick_breaking/code/V7/MPK/MPK/R/mpk.R",
    "project_path" : "R/mpk.R",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}